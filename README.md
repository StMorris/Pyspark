# Pyspark

### To support Python with Spark, Apache Spark community released a tool, PySpark. PySpark is a Python API for Apache Spark.
### Apache Spark is written in Scala programming language. 

#### Apache Spark is an analytical processing engine for large scale powerful distributed data processing and machine learning applications.


#### PySpark lets us work with RDDs in Python programming language, thanks to a library called Py4j that they are able to achieve this. Py4J is a Java library that is integrated within PySpark and allows python to dynamically interface with JVM (Java virtual machine) objects, hence to run PySpark you also need Java to be installed along with Python, and Apache Spark.
#### PySpark supports most of Sparkâ€™s features such as Spark SQL, DataFrame, Streaming, MLlib (Machine Learning) and Spark Core.

#### PySpark is very well used in Data Science and Machine Learning community due to its efficient processing of large datasets.
